----- SLIDE 1 -----
Introduction to Causal Inference
SciPy 2024
Roni Kobrosly Ph.D.
[Contains a diagram with nodes labeled A, B, C, D, E, F, G, H, I]

----- SLIDE 2 -----
[Contains screenshots of blog posts/articles:]
- Netflix Technology Blog: "A Survey of Causal Inference Applications at Netflix"
- Twitter Engineering post about Economics Nobel Prize winners
- "Causal Forecasting at Lyft (Part 1)" by DJ Rich
- LinkedIn article: "Ocelot: Scaling observational causal inference at LinkedIn"
- "How to Pick a Metric as the North Star for Algorithms to Optimize Business KPI? A Causal Inference Approach"

----- SLIDE 3 -----
By the end of this tutorial, you should be able to
- Understand the pitfalls of observational data analysis
- Know the various types of causal relationships to look out for
- Describe the hierarchy of statistical analyses, causal inference, and experiments
- Start conducting preliminary causal analyses on your own data
- Confidently explore the topic on your own (now that you have a solid foundational understanding of causal thinking)

----- SLIDE 4 -----
Hotel prices and bookings each week
[Contains a scatter plot showing the relationship between Price (USD) on x-axis (ranging from 10 to beyond 80) and Bookings Each Week on y-axis (ranging from 20 to 120), with a trend line showing positive correlation]

----- SLIDE 5 -----
Hotel prices and bookings each week

As a vacationer looking to avoid a crowded hotel:
this plot is good enough üëç

[Same scatter plot as previous slide]

----- SLIDE 6 -----
Hotel prices and bookings each week

As a hotel owner trying to optimize your pricing:
this plot is useless...

[Same scatter plot as previous slides]

----- SLIDE 7 -----
[Two images of vintage brass alarm clocks on striped fabric backgrounds]

----- SLIDE 8 -----
[Black and white historical photograph showing women working at a long table in a factory or workshop setting with large windows]

----- SLIDE 9 -----
Does exposure to this radium clock cause cancer?

----- SLIDE 10 -----
... what happens in an alternative universe?

Our Observed reality
[Icon of person]
Early 1980
Starts sleeping near clock
Lives their life
Develops cancer
[Hospital icon]

----- SLIDE 11 -----
... what happens in an alternative universe?

Our Observed reality
[Icon of person]
Early 1980
Starts sleeping near clock
Lives their life
Develops cancer
[Hospital icon]

An alternative reality
[Peace sign hand icon]
Early 1980
Throws out clock upon discovery

----- SLIDE 12 -----
... what happens in an alternative universe?

Our Observed reality
[Icon of person]
Early 1980
Starts sleeping near clock
Lives their life
Develops cancer
[Hospital icon]

An alternative reality
[Peace sign hand icon]
Early 1980
Throws out clock upon discovery
Lives their life
Does not develop cancer
[Smiling emoji]

----- SLIDE 13 -----
Counterfactuals ("Counter to fact")
[Image of book cover: "Altered Pasts: Counterfactuals in History" by Richard J. Evans showing a Chinese flag on the moon with an astronaut]
[Diagram showing "Similarity Analysis" with circles representing œÜ-worlds and œà-worlds, with labels for "Antecedent œÜ", "Consequent œà", "Variable Domain", and "System of Spheres of Similarity"]

----- SLIDE 14 -----
You can also think of counterfactuals as a missing data problem

| ID# | special offer | age | device  | churn? |
|-----|--------------|-----|---------|--------|
| 1   | Y            | 40  | iphone  | Y      |
| 2   | Y            | 35  | android | N      |
| 3   | N            | 77  | iphone  | N      |
| 4   | Y            | 18  | android | N      |

----- SLIDE 15 -----
| ID# | Did we observe this? | special offer | age | device  | churn? |
|-----|---------------------|--------------|-----|---------|--------|
| 1   | Y                   | Y            | 40  | iphone  | Y      |
| 1   | N                   | N            | 40  | iphone  | ???    |
| 2   | Y                   | Y            | 35  | android | N      |
| 2   | N                   | N            | 35  | android | ???    |
| 3   | N                   | Y            | 77  | iphone  | ???    |
| 3   | Y                   | N            | 77  | iphone  | N      |
| 4   | Y                   | Y            | 18  | android | N      |
| 4   | N                   | N            | 18  | android | ???    |

----- SLIDE 16 -----
Experiments (AKA A/B Tests, AKA Randomized Controlled Trials)

Treatment group
[Icons of 5 people]

Control group
[Icons of 5 people]

----- SLIDE 17 -----
Experiments (AKA A/B Tests, AKA Randomized Controlled Trials)

Treatment group
[Icons of 5 people]
‚Üí shown special offer upon canceling service

Control group
[Icons of 5 people]
‚Üí not shown special offer upon canceling service

----- SLIDE 18 -----
Experiments (AKA A/B Tests, AKA Randomized Controlled Trials)

Treatment group
[Icons of 5 people]
‚Üí shown special offer upon canceling service
‚Üí See how many people continue using service

Control group
[Icons of 5 people]
‚Üí not shown special offer upon canceling service
‚Üí See how many people continue using service

----- SLIDE 19 -----
... but sometimes experiments aren't feasible

‚óè Examples:
  ‚óã Understanding how a user's behavior changes when they switch from an Iphone to the newest Samsung phone.
  ‚óã Too few units, such as in a Merger and Acquisition scenario (there is one event that may or may not happen)
  ‚óã Modify household incomes in neighborhoods, to see if reducing a neighborhood's income inequality reduces the local crime rate.

Kohavi et al. "Trustworthy Online Controlled Experiments." 2020

----- SLIDE 20 -----
... and sometimes experiments aren't ethical

‚óè Examples:
  ‚óã Randomly assign some people to be exposed to lead paint while others are not, then see which group is more likely to develop neurological disorders.
  ‚óã Assigning some social media users to receive more psychologically dark posts to understand how it impacts engagement.

----- SLIDE 21 -----
A simple hierarchy...

statistical associations / correlations
‚Üï
causal inference
‚Üï
randomized experiments

Weaker causal claims                    Stronger causal claims
Less easy                               Easier

----- SLIDE 22 -----
statistical associations / correlations
‚Üï
causal inference
‚Üï
randomized experiments

Note: I'm referring to RAW associations and correlations. Correlations are indispensable in causal inference work, but we make intelligent adjustments to them more valuable.

----- SLIDE 23 -----
Causal Inference vs Typical ML Project Questions

Causal Inference:
- How does improving neighborhood income inequality reduce neighborhood crime rate?
- How does increasing or decreasing the price of a product impact demand?
- What would be the impact on the number of people with diabetes if we enacted a policy to reduce the average amount of sugar consumed per day by X grams.

Typical ML:
- Can I cluster neighborhoods by their characteristics and tell a story about these different segments and how it relates to crime rates?
- Can I predict whether someone will convert from a lead to a customer?
- How well can I predict whether a patient will be diagnosed with diabetes later in life?

----- SLIDE 24 -----
A causal graph

[Diagram showing nodes A, B, C, D, E connected with directional arrows forming a simple causal graph]

----- SLIDE 25 -----
Three important types of causal relationships...

----- SLIDE 26 -----
1) Confounders

----- SLIDE 27 -----
Confounders

Treatment ‚Üí Outcome
???

----- SLIDE 28 -----
Confounders

Treatment ‚Üí Outcome
    ‚Üë         ‚Üë
    Confounder

----- SLIDE 29 -----
Confounders

‚óè Always want to control for / condition on confounders in inferential modeling
‚óè Confounding changes the effect size and possibly statistical significance of your association of interest
‚óè Confounders can also flip the direction of your association of interest
‚óè A model will ideally control for confounding, but leftover confounding in a model is named "residual confounding"

[Diagram showing:]
Presence of AirBnB in a neighborhood ‚Üí Neighborhood house prices
                ‚Üë                            ‚Üë
            Tourism Demand

----- SLIDE 30 -----
Confounders

‚óè Positive confounding: confounder introduces a bias that pushes association of interest away from the "null"
‚óè Negative confounding: confounder biases association towards the "null"

[Same diagram as previous slide:]
Presence of AirBnB in a neighborhood ‚Üí Neighborhood house prices
                ‚Üë                            ‚Üë
            Tourism Demand

----- SLIDE 31 -----
Violent crime in your city!

Ice cream sales ‚Üí Violent crime
???

----- SLIDE 32 -----
Summer weather induces a false association between ice cream sales and violent crime

Ice cream sales ‚Üí Violent crime
        ‚Üë              ‚Üë
    Hot Weather

----- SLIDE 33 -----
Summer weather induces a false association between ice cream sales and violent crime

Ice cream sales ‚Üí Violent crime
        ‚Üë              ‚Üë
    Hot Weather

----- SLIDE 34 -----
If you control for the season, any ice cream-violent crime association in your dataset will disappear

Ice cream sales ‚Üí Violent crime
        ‚Üë              ‚Üë
    Hot Weather

----- SLIDE 35 -----
This all sounds nice, but how do I "control" for things?

1) The simple/naive way:
- "Stratify" on the variable you want to control for
- AKA filter your dataset so that variable only takes on 1 value.
- For example, when calculating the following you're controlling for / conditioning on smoking status
  p(lung problems = 1 | smoker = 0)

2) Use a model!
- Sit tight, the second half of this tutorial goes deep on this topic

----- SLIDE 36 -----
How experiments break confounding

Classroom size ‚Üí Student performance
???

----- SLIDE 37 -----
How experiments break confounding

Classroom size ‚Üí Student performance
        ‚Üë              ‚Üë
???
Socioeconomic status of school

----- SLIDE 38 -----
How experiments break confounding

Classroom size ‚Üí Student performance
        ‚Üë              ‚Üë
???
Randomization in A/B tests      Socioeconomic status of school
break any association
between confounder and
treatment in the data

----- SLIDE 39 -----
Experiments or A/B tests are wonderful because the act of randomization breaks all confounding (treatment status is not allowed to be associated with any covariate)

Causal inference is when we take non-experimental data (AKA observational data) and carefully try to pick apart the confounding ourselves

----- SLIDE 40 -----
2) Colliders

----- SLIDE 41 -----
Colliders

Treatment ‚Üí Outcome
???

----- SLIDE 42 -----
Colliders

Treatment ‚Üí Outcome
        ‚Üì
    Collider

----- SLIDE 43 -----
Colliders

‚óè Never want to control for / condition on colliders
‚óè Conditioning on a common effect causes collider bias, which can be in positive or negative direction

[Diagram showing:]
smoking ‚Üí Lung Cancer
      ‚Üì
# of sick days taken

----- SLIDE 44 -----
3) Mediators

----- SLIDE 45 -----
Mediators

Treatment ‚Üí Outcome
???

----- SLIDE 46 -----
Mediators

Treatment ‚Üí Outcome
         ‚Üì
     Mediator

----- SLIDE 47 -----
Mediators

‚óè Controlling for a mediator will nullify associations of interest
‚óè There are statistical tests of mediation you can use to help determine causal relationships in observational data

[Diagram showing:]
Hours of rain on given day ‚Üí Daily profit from rideshare program
              ‚Üì
Rideshare requests from customer base

----- SLIDE 48 -----
Putting it all together

[Diagram showing:]
    Confounder
      ‚Üì    ‚Üì
Treatment ‚Üí Mediator ‚Üí Outcome
      ‚Üì
   Collider

----- SLIDE 49 -----
In reality, causality is complicated!

[Complex causal diagram showing relationships between multiple variables including:]
- Gestational Weight Gain
- Maternal Height
- Maternal pre pregnancy weight
- Chronic Hypertension
- Maternal Race
- Poverty Index
- Maternal Education
- Maternal Age
- Estimated Fetal Weight
- Caesarean Delivery
- PNC Site
- Pre-Eclampsia/Eclampsia

Hamra GB et al., "Model Averaging for Improving Inference from Causal Diagrams", 2015

----- SLIDE 50 -----
Notebook exercise #1:
Causal graphs

----- SLIDE 51 -----
Now some misc asides...

----- SLIDE 52 -----
Avoid automated causal graph structure learning, stick with good domain knowledge

[Three diagrams showing:]
A ‚Üí B ‚Üí C
A ‚Üê B ‚Üí C
A ‚Üê B ‚Üê C

These three graphs belong to the same "Markov Equivalence Class" and are indistinguishable with observational data!

----- SLIDE 53 -----
LLMs and causality

[Academic paper title page showing:]
Can Large Language Models Infer Causation from Correlation?

Zhijing Jin¬π'¬≤ Jiarui Liu¬≥ Zhiheng Lyu‚Å¥ Spencer Poff‚Åµ
Mrinmaya Sachan¬≤ Rada Mihalcea¬≥ Mona Diab‚Åµ'‚Ä† Bernhard Sch√∂lkopf¬π'‚Ä†
¬πMax Planck Institute for Intelligent Systems, T√ºbingen, Germany, ¬≤ETH Z√ºrich,
¬≥University of Michigan, ‚Å¥University of Hong Kong, ‚ÅµMeta AI

Abstract

Causal inference is one of the hallmarks of human intelligence. While the field of CausalNLP has attracted much interest in the recent years, existing causal inference datasets in NLP primarily rely on discovering causality from empirical knowledge (e.g. commonsense knowledge). In this work, we propose the first benchmark dataset to test the pure causal inference skills of large language models (LLMs). Specifically, we formulate a novel task CORR2CAUSE, which takes a (set of) correlational statements and determines the causal relationship between the variables. We curate a large-scale dataset of over 400K samples...

----- SLIDE 54 -----
[Figure showing training corpus examples and task description:]

Training Corpus:
Smoking causes cancer. [‚úì] Clear causal fact

Upon the release of the vaccines, the number of disease cases reached a historical high. [Shows neural network icon]

[Light bulb icon] We propose a new task: Corr2Cause Inference

Suppose we know that A correlates with B.
Can we infer that A causes B?

A correlates with C. B correlates with C. However, A is independent of B.
Can we infer that A and B have a common effect?

? How can LLMs process this information? Correlation? Causation? What causes what?

/ 
This requires the skill of inferring causation from correlation

Previous tasks:
Alice slipped, so she fell down. ‚Üí Plausible

Skill being tested in previous work: Empirical knowledge instead of pure causal inference.

Figure 1: Illustration of the motivation behind our task and dataset.

----- SLIDE 55 -----
[Table showing model performance:]

|                              | F1    | Precision | Recall | Accuracy |
|------------------------------|-------|-----------|--------|----------|
| Random Baselines             |       |           |        |          |
| Always Majority              | 0.0   | 0.0       | 0.0    | 84.77    |
| Random (Proportional)        | 13.5  | 12.53     | 14.62  | 71.46    |
| Random (Uniform)             | 20.38 | 15.11     | 31.29  | 62.78    |
| BERT-Based Models            |       |           |        |          |
| BERT MNLI                    | 2.82  | 7.23      | 1.75   | 81.61    |
| RoBERTa MNLI                 | 22.79 | 34.73     | 16.96  | 82.50    |
| DeBERTa MNLI                 | 14.52 | 14.71     | 14.33  | 74.31    |
| DistilBERT MNLI              | 20.70 | 24.12     | 18.13  | 78.85    |
| DistilBART MNLI              | 26.74 | 15.92     | 83.63  | 30.23    |
| BART MNLI                    | 33.38 | 31.59     | 35.38  | 78.50    |
| LLaMa-Based Models           |       |           |        |          |
| LLaMa-6.7B                   | 26.81 | 15.50     | 99.42  | 17.36    |
| Alpaca-6.7B                  | 27.37 | 15.93     | 97.37  | 21.33    |
| GPT-Based Models             |       |           |        |          |
| GPT-3 Ada                    | 0.00  | 0.00      | 0.00   | 84.77    |
| GPT-3 Babbage                | 27.45 | 15.96     | 97.95  | 21.15    |
| GPT-3 Curie                  | 26.43 | 15.23     | 100.00 | 15.23    |
| GPT-3 Davinci                | 27.82 | 16.57     | 86.55  | 31.61    |
| GPT-3 Instruct (text-davinci-001) | 17.99 | 11.84 | 37.43  | 48.04    |
| GPT-3 Instruct (text-davinci-002) | 21.87 | 13.46 | 58.19  | 36.69    |
| GPT-3 Instruct (text-davinci-003) | 15.72 | 13.4  | 19.01  | 68.97    |
| GPT-3.5                      | 21.69 | 17.79     | 27.78  | 69.46    |
| GPT-4                        | 29.08 | 20.92     | 47.66  | 64.60    |

Table 4: Overall performance. We report F1 (main metric), precision, recall and accuracy. For the main metric, F1 score, we use the bold font to highlight the overall best performance, and underline to highlight the best performance within each category of models.

----- SLIDE 56 -----
[Two tables showing finetuned model performance:]

Table (a):
|                               | F1    | Precison | Recall | Accuracy |
|-------------------------------|-------|----------|--------|----------|
| Finetuned GPT-Based Models    |       |          |        |          |
| GPT-3 Ada                     | 79.85 | 70.47    | 92.11  | 92.92    |
| GPT-3 Babbage                 | 78.19 | 69.98    | 88.60  | 92.48    |
| GPT-3 Curie                   | 81.23 | 75.00    | 88.60  | 93.77    |
| GPT-3 Davinci                 | 85.52 | 80.26    | 91.52  | 95.28    |
| Finetuned BERT-Based Models   |       |          |        |          |
| BERT-Base                     | 69.29 | 54.42    | 95.32  | 87.13    |
| BERT-Large                    | 85.26 | 77.51    | 94.74  | 95.01    |
| RoBERTa-Base                  | 87.60 | 78.47    | 99.12  | 95.73    |
| RoBERTa-Large                 | 89.10 | 82.54    | 96.78  | 96.39    |
| Finetuned BERT-Based NLI Models |     |          |        |          |
| BERT-Base MNLI                | 89.88 | 85.49    | 94.74  | 86.51    |
| BERT-Large MNLI               | 90.19 | 84.44    | 96.78  | 96.79    |
| RoBERTa-Base MNLI             | 94.27 | 90.35    | 98.54  | 98.17    |
| RoBERTa-Large MNLI            | 94.74 | 92.24    | 97.37  | 98.35    |

Table (b):
|                               | F1 (Paraph.) | F1 (Var. Ref.) |
|-------------------------------|--------------|----------------|
| GPT-3 Ada                     | 61.73        | 41.57          |
| GPT-3 Babbage                 | 62.34        | 43.28          |
| GPT-3 Curie                   | 64.93        | 45.32          |
| GPT-3 Davinci                 | 65.01        | 46.96          |
| BERT-Base                     | 61.13        | 35.20          |
| BERT-Large                    | 63.64        | 38.54          |
| RoBERTa-Base                  | 65.58        | 53.12          |
| RoBERTa-Large                 | 65.05        | 60.20          |
| BERT-Base MNLI                | 65.56        | 31.50          |
| BERT-Large MNLI               | 67.24        | 52.04          |
| RoBERTa-Base MNLI             | 57.42        | 62.83          |
| RoBERTa-Large MNLI            | 55.45        | 67.87          |

(a) Performance of finetuned models on the original test set.
(b) F1 scores of finetuned models on the perturbed test sets by paraphrasing (Paraph.) and variable refactorization (Var. Ref.).

Table 5: Performance of finetuned models on the original test set and perturbed test sets.

----- SLIDE 57 -----
Nota bene!

Traditional variable importance methods don't tell you anything about causality!

[Bar chart showing feature importance with "title" having the highest value (~0.16), followed by "ticket_class", "deck", "num_family", "age", "ticket_price", "surname_length", "random", "emb_Q", "is_female", "emb_C", "emb_S". X-axis shows "mean(|SHAP value|) (average impact on model output magnitude)" ranging from 0.00 to 0.16]

----- SLIDE 58 -----
We've discussed three types of causal relationships. Going forward, we're going to assume you identified key confounders you want to control for, as you estimate the causal impact between a "treatment" and an "outcome"...

----- SLIDE 59 -----
If you are doing causal modeling...

‚óè First, think carefully about quantities of interest and their relationships before looking at any data - this requires domain knowledge
‚óè Stick with a small set of important variables that you have domain knowledge on.
‚óè Before modeling, understand bivariate relationships between independent vars, also between independent vars and dependent var
‚óè Identify potential confounders and identify covariates not to control for

----- SLIDE 60 -----
Assumptions of causal inference

‚óè Temporality. Causes always occur before effects: The treatment variable needs to occur before measured outcome. Covariates should occur before treatment (prevents you from controlling on colliders).
‚óè Stable Unit Treatment Value. The treatment status of a given individual does not affect the potential outcomes of any other individuals.
‚óè Positivity. For each level of each covariate in your data, there needs to be some variability of the treatment and outcome variables.
‚óè Ignorability. All major confounding variables are included in your data. This is a tough one, but necessary to get an unbiased estimate of the treatment effect.

----- SLIDE 61 -----
Example #1

I want to understand whether frequent emails to customers might impact customer satisfaction.

I have survey data with customer, self-reported satisfaction from a year ago, and I use this past month's number of emails for each customer as a proxy for how often we email them generally.

----- SLIDE 62 -----
Example #2

I want to see the causal impact of a neighborhood's cleanliness on crime rates, controlling for 20 known confounders.

I pull up an academic dataset with data on 40 distinct neighborhoods. So, my sample size is 40.

----- SLIDE 63 -----
Example #3

I want to see how releasing a new in-app, multiplayer game through my social media app impacts user engagement. I only want to give it to some test users initially.

With this multiplayer game you can play with anyone who has the social media app by sending them invites. Accidentally, our test users can invite non-test users.

----- SLIDE 64 -----
Example #4

We're curious how a job training program could impact a person's income 3 years in the future.

Unfortunately we don't have lots of data on the participants so we perform a causal inference analysis only controlling for the person's age.

----- SLIDE 65 -----
Metrics

----- SLIDE 66 -----
Counterfactuals (with a binary treatment)

Our Observed reality
[Person icon]

An alternative reality
[Peace sign hand icon]

----- SLIDE 67 -----
Counterfactuals (with a binary treatment)

Our Observed reality
[Person icon]
Experiences 500 ms delay on website

An alternative reality
[Peace sign hand icon]
Experiences no delay on website

----- SLIDE 68 -----
Counterfactuals (with a binary treatment)

Our Observed reality
[Person icon]
Experiences 500 ms delay on website ‚Üí Clicks through webpage

An alternative reality
[Peace sign hand icon]
Experiences no delay on website ‚Üí Clicks through webpage?

----- SLIDE 69 -----
Counterfactuals (with a binary treatment)

Our Observed reality
[Person icon]
Experiences 500 ms delay on website ‚Üí Clicks through webpage ‚Üí Œî

An alternative reality
[Peace sign hand icon]
Experiences no delay on website ‚Üí Clicks through webpage? ‚Üí Œî

----- SLIDE 70 -----
Counterfactuals (with a binary treatment)

Our Observed reality
[Group of 6 person icons]
Experiences 500 ms delay on website ‚Üí Click through rate (CTR) ‚Üí Average Treatment Effect

An alternative reality
[Group of 6 person icons]
Experiences no delay on website ‚Üí Click through rate (CTR) ‚Üí Average Treatment Effect

----- SLIDE 71 -----
Nota bene:
you can apply causal inference to any unit of analysis (people, browser sessions, webpages, clusters of friends when working with social media data, neighborhoods, buildings, pharmacies, etc.)

----- SLIDE 72 -----
Metrics

| Population                         | Metric name                                    |
|------------------------------------|------------------------------------------------|
| Effect in entire population        | Average Treatment Effect (ATE)                 |
| Effect in treated population       | Average Treatment Effect Among Treated (ATT)   |
| Effect in untreated population     | Average Treatment Effect Among Untreated (ATU) |
| Effect for a single unit of analysis (e.g. person) | Individual Treatment Effect (ITE)    |

----- SLIDE 73 -----
Metrics

| Population                                          | Metric name                                                        |
|-----------------------------------------------------|--------------------------------------------------------------------|
| Effect in segmented by some covariate              | Conditional Average Treatment Effect (CATE)                        |
| Effect in treated population segmented by some covariate | Conditional Average Treatment Effect Among Treated (CATT)    |
| Effect in untreated population segmented by some covariate | Conditional Average Treatment Effect Among Untreated (CATU) |

----- SLIDE 74 -----
Modeling approaches for causal inference

----- SLIDE 75 -----
Interrupted Time Series

[Graph showing:]
- Y-axis: outcome
- X-axis: time
- Vertical dashed line labeled "intervention"
- Solid line showing "observed trend" increasing after intervention
- Dashed line showing "underlying trend (or counterfactual trend)" with lower slope after intervention point

----- SLIDE 76 -----
Regression Discontinuity Design

[Graph showing:]
- Y-axis: numbered 0-60
- X-axis: "Baseline poverty index (20-100)" numbered 20-100
- Vertical line at x=58 dividing "Eligible" and "Not eligible" regions
- Scatter plot with two distinct regression lines showing discontinuity at cutoff
- Points A and B marked at the discontinuity

----- SLIDE 77 -----
Difference in Differences

[Graph showing:]
- Y-axis: Outcome
- X-axis: Pre-intervention and Post-intervention periods separated by vertical line
- Blue line: "Observed outcome trend in intervention group" (starting low, ending high)
- Red line: "Observed outcome trend in intervention group" (starting mid-level, curving up)
- Green line: "Observed outcome trend in comparison group" (starting low, gradually increasing)
- Dotted line showing "Unobserved Counterfactual outcome trend for intervention group"
- Labels indicating "Constant difference in outcome" and "Intervention effect"

----- SLIDE 78 -----
Propensity score matching (PSM)

[Diagram showing:]
Start with some population from observational data
[Group of 9 person icons]
‚Üí
Divide group into those that received and didn't receive treatment. Match each treatment unit with a similar control unit.
[Two groups of 3 person icons each labeled "Treatment" and "Controls" with bidirectional arrows between matching pairs]
‚Üí
Œî
Compare outcomes values between the two groups

----- SLIDE 79 -----
1) Start with a set of participants for whom we have complete treatment, outcome, and covariate data

| ID# | Covar 1 | Covar 2 | treat | outcome |
|-----|---------|---------|-------|---------|
| 1   | ...     | ...     | 1     | 20      |
| 2   | ...     | ...     | 1     | 15      |
| 3   | ...     | ...     | 0     | 10      |
| 4   | ...     | ...     | 0     | 10      |
| 5   | ...     | ...     | 1     | 20      |

----- SLIDE 80 -----
2) For all participants, calculate probability of them receiving treatment, based on covariate data (a propensity score)

| ID# | Covar 1 | Covar 2 | treat | ps   | outcome |
|-----|---------|---------|-------|------|---------|
| 1   | ...     | ...     | 1     | 0.65 | 20      |
| 2   | ...     | ...     | 1     | 0.33 | 15      |
| 3   | ...     | ...     | 0     | 0.64 | 10      |
| 4   | ...     | ...     | 0     | 0.33 | 10      |
| 5   | ...     | ...     | 1     | 0.97 | 20      |

----- SLIDE 81 -----
3) Take sub-sample of treated participants and match to sub-sample of control participants, based on similar ps values

| ID# | Covar 1 | Covar 2 | treat | ps   | outcome |
|-----|---------|---------|-------|------|---------|
| 1   | ...     | ...     | 1     | 0.65 | 20      |
| 3   | ...     | ...     | 0     | 0.64 | 10      |

| ID# | Covar 1 | Covar 2 | treat | ps   | outcome |
|-----|---------|---------|-------|------|---------|
| 2   | ...     | ...     | 1     | 0.33 | 15      |
| 4   | ...     | ...     | 0     | 0.33 | 10      |

----- SLIDE 82 -----
4) Calculate treatment effect on these two sub-samples using standard approaches

| ID# | Covar 1 | Covar 2 | treat | ps   | outcome |
|-----|---------|---------|-------|------|---------|
| 1   | ...     | ...     | 1     | 0.65 | 20      |
| 2   | ...     | ...     | 1     | 0.33 | 15      |
| 3   | ...     | ...     | 0     | 0.64 | 10      |
| 4   | ...     | ...     | 0     | 0.33 | 10      |

Average treatment effect among matched participants = xÃÑ_treated - xÃÑ_untreated = (20 + 15)/2 - (10 + 10)/2 = 7.5

----- SLIDE 83 -----
Modeling approaches for causal inference:
G-computation / S-learner

----- SLIDE 84 -----
1) Start with a set of participants for whom we have complete treatment, outcome, and covariate data

| ID# | Covar 1 | Covar 2 | treat | outcome |
|-----|---------|---------|-------|---------|
| 1   | ...     | ...     | 1     | 20      |
| 2   | ...     | ...     | 1     | 15      |
| 3   | ...     | ...     | 0     | 10      |
| 4   | ...     | ...     | 0     | 10      |
| 5   | ...     | ...     | 1     | 20      |

----- SLIDE 85 -----
2) Train a model that predicts the outcome from all covariates and treatment variable. Aim for high recall and precision.

[Scikit-learn logo]

| ID# | Covar 1 | Covar 2 | treat | outcome |
|-----|---------|---------|-------|---------|
| 1   | ...     | ...     | 1     | 20      |
| 2   | ...     | ...     | 1     | 15      |
| 3   | ...     | ...     | 0     | 10      |
| 4   | ...     | ...     | 0     | 10      |
| 5   | ...     | ...     | 1     | 20      |

----- SLIDE 86 -----
3) "Force" every observation in the dataset to receive the treatment

| ID# | Covar 1 | Covar 2 | treat | outcome |
|-----|---------|---------|-------|---------|
| 1   | ...     | ...     | 1     | 20      |
| 2   | ...     | ...     | 1     | 15      |
| 3   | ...     | ...     | 1     | 10      |
| 4   | ...     | ...     | 1     | 10      |
| 5   | ...     | ...     | 1     | 20      |

----- SLIDE 87 -----
4) Predict outcome values with these covariate and treatment values

| ID# | Covar 1 | Covar 2 | treat | outcome | ≈∑‚ÇÅ   |
|-----|---------|---------|-------|---------|------|
| 1   | ...     | ...     | 1     | 20      | 22.5 |
| 2   | ...     | ...     | 1     | 15      | 16.0 |
| 3   | ...     | ...     | 1     | 10      | 14.0 |
| 4   | ...     | ...     | 1     | 10      | 17.0 |
| 5   | ...     | ...     | 1     | 20      | 22.5 |

----- SLIDE 88 -----
5) Now "force" every observation to not receive treatment,
And make outcome predictions again

| ID# | Covar 1 | Covar 2 | treat | outcome | ≈∑‚ÇÅ   | ≈∑‚ÇÄ   |
|-----|---------|---------|-------|---------|------|------|
| 1   | ...     | ...     | 0     | 20      | 22.5 | 18.5 |
| 2   | ...     | ...     | 0     | 15      | 16.0 | 14.0 |
| 3   | ...     | ...     | 0     | 10      | 14.0 | 11.5 |
| 4   | ...     | ...     | 0     | 10      | 17.0 | 13.0 |
| 5   | ...     | ...     | 0     | 20      | 22.5 | 19.5 |

----- SLIDE 89 -----
6) Calculate the average difference between treated and untreated outcome estimates. This is the conditional average treatment effect (CATE)

| ID# | ≈∑‚ÇÅ   | ≈∑‚ÇÄ   | Œî·µ¢  |
|-----|------|------|-----|
| 1   | 22.5 | 18.5 | 4.0 |
| 2   | 16.0 | 14.0 | 2.0 |
| 3   | 14.0 | 11.5 | 2.5 |
| 4   | 17.0 | 13.0 | 4.0 |
| 5   | 22.5 | 19.5 | 3.0 |

‚Üì
Œº_Œî = 3.1

----- SLIDE 90 -----
Notebook exercise #2

----- SLIDE 91 -----
Closing thoughts: the perils of multiple testing...

[Journal article header showing:]
Statistics

Priya Ranganathan,
C. S. Pramesh¬π,
Marc Buyse¬≤'¬≥

Department of Anaesthesiology,
Tata Memorial Centre, ¬πDepartment
of Surgical Oncology, Division of
Thoracic Surgery, Tata Memorial
Centre, Mumbai, Maharashtra, India,
¬≤International Drug Development
Institute, San Francisco, California,
USA, ¬≥Department of Biostatistics,
Hasselt University, Hasselt, Belgium

Common pitfalls in statistical analysis:
The perils of multiple testing

----- SLIDE 92 -----
Closing thoughts: be humble, it's likely your research or business idea doesn't work!

[O'REILLY website screenshot showing:]
TEAMS    INDIVIDUALS    FEATURES    BLOG    CONTENT SPONSORSHIP    [Search icon]

Radar / Business

The Sobering Truth About the Impact of Your Business Ideas

By Eric Colson, Daragh Sibley and Dave Spiegel

October 26, 2021

----- SLIDE 93 -----
Closing thoughts: troubleshooting

‚óè Having domain knowledge and understanding the data-generating process is often way more productive than just throwing an algo at the problem
‚óè There is value in trying multiple techniques to understand their range of estimates (but use p-value correction if you're running lots of analyses)
‚óè You'll never be able to capture all confounders, but do aim to capture the major ones
‚óè If your results don't make sense and your code isn't buggy, you're probably missing a big source of bias
‚óè Causal inference and modeling is powerful but still not as trustworthy as running a proper experiment. Approach all results with healthy skepticism.